{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":375021,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":310003,"modelId":330371}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tensorboardX catboost","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-07T02:09:33.890718Z","iopub.execute_input":"2025-05-07T02:09:33.891007Z","iopub.status.idle":"2025-05-07T02:09:38.839461Z","shell.execute_reply.started":"2025-05-07T02:09:33.890987Z","shell.execute_reply":"2025-05-07T02:09:38.838443Z"}},"outputs":[{"name":"stdout","text":"Collecting tensorboardX\n  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.7)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (24.2)\nRequirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (3.20.3)\nRequirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.7.5)\nRequirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.3)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.2)\nRequirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\nRequirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.1)\nRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.0.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->tensorboardX) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->tensorboardX) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->tensorboardX) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->tensorboardX) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->tensorboardX) (2024.2.0)\nDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: tensorboardX\nSuccessfully installed tensorboardX-2.6.2.2\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import shutil\nimport os\n\nsource_dir = '/kaggle/input/ball-detect-train-dataset/datasets'\ndest_dir = '/kaggle/working/datasets'\n\nshutil.copytree(source_dir, dest_dir)\n\nprint(\"✅ Dataset copied successfully!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport catboost as ctb\nfrom scipy.spatial import distance\nfrom itertools import groupby\nfrom tensorboardX import SummaryWriter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T02:09:50.107932Z","iopub.execute_input":"2025-05-07T02:09:50.108269Z","iopub.status.idle":"2025-05-07T02:10:09.349372Z","shell.execute_reply.started":"2025-05-07T02:09:50.108244Z","shell.execute_reply":"2025-05-07T02:10:09.348590Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"#GT folder generation \n# GT Generation Configuration\nSIZE = 30\nVARIANCE = 15 \nWIDTH = 1280\nHEIGHT = 720\n\ndef gaussian_kernel(size, variance):\n    x, y = np.mgrid[-size:size+1, -size:size+1]\n    g = np.exp(-(x**2+y**2)/float(2*variance))\n    return g\n\ndef create_gaussian(size, variance):\n    gaussian_kernel_array = gaussian_kernel(size, variance)\n    gaussian_kernel_array = gaussian_kernel_array * 255/gaussian_kernel_array[int(len(gaussian_kernel_array)/2)][int(len(gaussian_kernel_array)/2)]\n    gaussian_kernel_array = gaussian_kernel_array.astype(int)\n    return gaussian_kernel_array","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#GT cell-2\ndef create_gt_images(path_input, path_output):\n    gaussian_kernel_array = create_gaussian(SIZE, VARIANCE)\n    for game_id in range(1,11):\n        game = 'game{}'.format(game_id)\n        clips = os.listdir(os.path.join(path_input, game))\n        for clip in clips:\n            print('Generating GT for game = {}, clip = {}'.format(game, clip))\n\n            path_out_game = os.path.join(path_output, game)\n            os.makedirs(path_out_game, exist_ok=True)\n\n            path_out_clip = os.path.join(path_out_game, clip)    \n            os.makedirs(path_out_clip, exist_ok=True)\n\n            path_labels = os.path.join(path_input, game, clip, 'Label.csv')\n            labels = pd.read_csv(path_labels)    \n            for idx in range(labels.shape[0]):\n                file_name, vis, x, y, _ = labels.loc[idx, :]\n                heatmap = np.zeros((HEIGHT, WIDTH, 3), dtype=np.uint8)\n                if vis != 0:\n                    x = int(x)\n                    y = int(y)\n                    for i in range(-SIZE, SIZE+1):\n                        for j in range(-SIZE, SIZE+1):\n                                if x+i<WIDTH and x+i>=0 and y+j<HEIGHT and y+j>=0:\n                                    temp = gaussian_kernel_array[i+SIZE][j+SIZE]\n                                    if temp > 0:\n                                        heatmap[y+j,x+i] = (temp,temp,temp)\n\n                cv2.imwrite(os.path.join(path_out_clip, file_name), heatmap)\n    print(\"GT image generation complete!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#GT cell-3\ndef create_gt_labels(path_input, path_output, train_rate=0.7):\n    df = pd.DataFrame()\n    for game_id in range(1,11):\n        game = 'game{}'.format(game_id)\n        clips = os.listdir(os.path.join(path_input, game))\n        for clip in clips:\n            labels = pd.read_csv(os.path.join(path_input, game, clip, 'Label.csv'))\n            labels['gt_path'] = 'gts/' + game + '/' + clip + '/' + labels['file name']\n            labels['path1'] = 'images/' + game + '/' + clip + '/' + labels['file name']\n            labels_target = labels[2:]\n            labels_target.loc[:, 'path2'] = list(labels['path1'][1:-1])\n            labels_target.loc[:, 'path3'] = list(labels['path1'][:-2])\n            df = pd.concat([df, labels_target])\n    \n    df = df.reset_index(drop=True) \n    df = df[['path1', 'path2', 'path3', 'gt_path', 'x-coordinate', 'y-coordinate', 'status', 'visibility']]\n    df = df.sample(frac=1)\n    num_train = int(df.shape[0]*train_rate)\n    df_train = df[:num_train]\n    df_test = df[num_train:]\n    \n    os.makedirs(path_output, exist_ok=True)\n    df_train.to_csv(os.path.join(path_output, 'labels_train.csv'), index=False)\n    df_test.to_csv(os.path.join(path_output, 'labels_val.csv'), index=False)\n    print(\"Label CSVs created successfully!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set your paths (modify according to your Kaggle dataset structure)\nINPUT_PATH = '/kaggle/input/ball-detect-train-dataset/datasets/trackNet/images'  # Where original data is\nOUTPUT_PATH = '/kaggle/working/datasets/trackNet'  # Where to save generated data\n\n# Run the generation\ncreate_gt_images(INPUT_PATH, os.path.join(OUTPUT_PATH, 'gts'))\ncreate_gt_labels(INPUT_PATH, OUTPUT_PATH)\n\nprint(\"Ground truth generation complete!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#dataset class\nclass trackNetDataset(Dataset):\n    def __init__(self, mode, input_width=1280 , input_height=720):\n        self.path_dataset = '/kaggle/working/datasets/trackNet'  # Update path as needed\n        assert mode in ['train', 'val'], 'incorrect mode'\n        self.data = pd.read_csv(os.path.join(self.path_dataset, 'labels_{}.csv'.format(mode)))\n        print('mode = {}, samples = {}'.format(mode, self.data.shape[0]))         \n        self.height = input_height\n        self.width = input_width\n        \n    def __len__(self):\n        return self.data.shape[0]\n    \n    def __getitem__(self, idx):\n        path, path_prev, path_preprev, path_gt, x, y, status, vis = self.data.loc[idx, :]\n        \n        path = os.path.join(self.path_dataset, path)\n        path_prev = os.path.join(self.path_dataset, path_prev)\n        path_preprev = os.path.join(self.path_dataset, path_preprev)\n        path_gt = os.path.join(self.path_dataset, path_gt)\n        if math.isnan(x):\n            x = -1\n            y = -1\n        \n        inputs = self.get_input(path, path_prev, path_preprev)\n        outputs = self.get_output(path_gt)\n        \n        return inputs, outputs, x, y, vis\n    \n    def get_output(self, path_gt):\n        img = cv2.imread(path_gt)\n        img = cv2.resize(img, (self.width, self.height))\n        img = img[:, :, 0]\n        img = np.reshape(img, (self.width * self.height))\n        return img\n        \n    def get_input(self, path, path_prev, path_preprev):\n        img = cv2.imread(path)\n        img = cv2.resize(img, (self.width, self.height))\n\n        img_prev = cv2.imread(path_prev)\n        img_prev = cv2.resize(img_prev, (self.width, self.height))\n        \n        img_preprev = cv2.imread(path_preprev)\n        img_preprev = cv2.resize(img_preprev, (self.width, self.height))\n        \n        imgs = np.concatenate((img, img_prev, img_preprev), axis=2)\n        imgs = imgs.astype(np.float32)/255.0\n\n        imgs = np.rollaxis(imgs, 2, 0)\n        return imgs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T02:10:18.940807Z","iopub.execute_input":"2025-05-07T02:10:18.941900Z","iopub.status.idle":"2025-05-07T02:10:18.952261Z","shell.execute_reply.started":"2025-05-07T02:10:18.941866Z","shell.execute_reply":"2025-05-07T02:10:18.951472Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"#Model defination\n\nclass ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size=3, pad=1, stride=1, bias=True):\n        super().__init__()\n        self.block = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=pad, bias=bias),\n            nn.ReLU(),\n            nn.BatchNorm2d(out_channels)\n        )\n\n    def forward(self, x):\n        return self.block(x)\n\nclass BallTrackerNet(nn.Module):\n    def __init__(self, out_channels=256):\n        super().__init__()\n        self.out_channels = out_channels\n\n        self.conv1 = ConvBlock(in_channels=9, out_channels=64)\n        self.conv2 = ConvBlock(in_channels=64, out_channels=64)\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv3 = ConvBlock(in_channels=64, out_channels=128)\n        self.conv4 = ConvBlock(in_channels=128, out_channels=128)\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv5 = ConvBlock(in_channels=128, out_channels=256)\n        self.conv6 = ConvBlock(in_channels=256, out_channels=256)\n        self.conv7 = ConvBlock(in_channels=256, out_channels=256)\n        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv8 = ConvBlock(in_channels=256, out_channels=512)\n        self.conv9 = ConvBlock(in_channels=512, out_channels=512)\n        self.conv10 = ConvBlock(in_channels=512, out_channels=512)\n        self.ups1 = nn.Upsample(scale_factor=2)\n        self.conv11 = ConvBlock(in_channels=512, out_channels=256)\n        self.conv12 = ConvBlock(in_channels=256, out_channels=256)\n        self.conv13 = ConvBlock(in_channels=256, out_channels=256)\n        self.ups2 = nn.Upsample(scale_factor=2)\n        self.conv14 = ConvBlock(in_channels=256, out_channels=128)\n        self.conv15 = ConvBlock(in_channels=128, out_channels=128)\n        self.ups3 = nn.Upsample(scale_factor=2)\n        self.conv16 = ConvBlock(in_channels=128, out_channels=64)\n        self.conv17 = ConvBlock(in_channels=64, out_channels=64)\n        self.conv18 = ConvBlock(in_channels=64, out_channels=self.out_channels)\n\n        self.softmax = nn.Softmax(dim=1)\n        self._init_weights()\n                  \n    def forward(self, x, testing=False): \n        batch_size = x.size(0)\n        x = self.conv1(x)\n        x = self.conv2(x)    \n        x = self.pool1(x)\n        x = self.conv3(x)\n        x = self.conv4(x)\n        x = self.pool2(x)\n        x = self.conv5(x)\n        x = self.conv6(x)\n        x = self.conv7(x)\n        x = self.pool3(x)\n        x = self.conv8(x)\n        x = self.conv9(x)\n        x = self.conv10(x)\n        x = self.ups1(x)\n        x = self.conv11(x)\n        x = self.conv12(x)\n        x = self.conv13(x)\n        x = self.ups2(x)\n        x = self.conv14(x)\n        x = self.conv15(x)\n        x = self.ups3(x)\n        x = self.conv16(x)\n        x = self.conv17(x)\n        x = self.conv18(x)\n        out = x.reshape(batch_size, self.out_channels, -1)\n        if testing:\n            out = self.softmax(out)\n        return out                       \n    \n    def _init_weights(self):\n        for module in self.modules():\n            if isinstance(module, nn.Conv2d):\n                nn.init.uniform_(module.weight, -0.05, 0.05)\n                if module.bias is not None:\n                    nn.init.constant_(module.bias, 0)\n            elif isinstance(module, nn.BatchNorm2d):\n                nn.init.constant_(module.weight, 1)\n                nn.init.constant_(module.bias, 0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T02:10:26.266798Z","iopub.execute_input":"2025-05-07T02:10:26.267419Z","iopub.status.idle":"2025-05-07T02:10:26.283180Z","shell.execute_reply.started":"2025-05-07T02:10:26.267378Z","shell.execute_reply":"2025-05-07T02:10:26.282287Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"#Utility functions\n\ndef postprocess(feature_map, scale=2):\n    feature_map *= 255\n    feature_map = feature_map.reshape((360, 640))\n    feature_map = feature_map.astype(np.uint8)\n    ret, heatmap = cv2.threshold(feature_map, 127, 255, cv2.THRESH_BINARY)\n    circles = cv2.HoughCircles(heatmap, cv2.HOUGH_GRADIENT, dp=1, minDist=1, param1=50, param2=2, minRadius=2,\n                               maxRadius=7)\n    x,y = None, None\n    if circles is not None:\n        if len(circles) == 1:\n            x = circles[0][0][0]*scale\n            y = circles[0][0][1]*scale\n    return x, y\n\ndef train(model, train_loader, optimizer, device, epoch, max_iters=200):\n    start_time = time.time()\n    losses = []\n    criterion = nn.CrossEntropyLoss()\n    for iter_id, batch in enumerate(train_loader):\n        optimizer.zero_grad()\n        model.train()\n        out = model(batch[0].float().to(device))\n        gt = torch.tensor(batch[1], dtype=torch.long, device=device)\n        loss = criterion(out, gt)\n\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        end_time = time.time()\n        duration = time.strftime(\"%H:%M:%S\", time.gmtime(end_time - start_time))\n        print('train | epoch = {}, iter = [{}|{}], loss = {}, time = {}'.format(epoch, iter_id, max_iters,\n                                                                                round(loss.item(), 6), duration))\n        losses.append(loss.item())\n        \n        if iter_id > max_iters - 1:\n            break\n        \n    return np.mean(losses)\n\ndef validate(model, val_loader, device, epoch, min_dist=5):\n    losses = []\n    tp = [0, 0, 0, 0]\n    fp = [0, 0, 0, 0]\n    tn = [0, 0, 0, 0]\n    fn = [0, 0, 0, 0]\n    criterion = nn.CrossEntropyLoss()\n    model.eval()\n    for iter_id, batch in enumerate(val_loader):\n        with torch.no_grad():\n            out = model(batch[0].float().to(device))\n            gt = torch.tensor(batch[1], dtype=torch.long, device=device)\n            loss = criterion(out, gt)\n            losses.append(loss.item())\n            # metrics\n            output = out.argmax(dim=1).detach().cpu().numpy()\n            for i in range(len(output)):\n                x_pred, y_pred = postprocess(output[i])\n                x_gt = batch[2][i]\n                y_gt = batch[3][i]\n                vis = batch[4][i]\n                if x_pred:\n                    if vis != 0:\n                        dst = distance.euclidean((x_pred, y_pred), (x_gt, y_gt))\n                        if dst < min_dist:\n                            tp[vis] += 1\n                        else:\n                            fp[vis] += 1\n                    else:        \n                        fp[vis] += 1\n                if not x_pred:\n                    if vis != 0:\n                        fn[vis] += 1\n                    else:\n                        tn[vis] += 1\n            print('val | epoch = {}, iter = [{}|{}], loss = {}, tp = {}, tn = {}, fp = {}, fn = {} '.format(epoch,\n                                                                                                            iter_id,\n                                                                                                            len(val_loader),\n                                                                                                            round(np.mean(losses), 6),\n                                                                                                            sum(tp),\n                                                                                                            sum(tn),\n                                                                                                            sum(fp),\n                                                                                                            sum(fn)))\n    eps = 1e-15\n    precision = sum(tp) / (sum(tp) + sum(fp) + eps)\n    vc1 = tp[1] + fp[1] + tn[1] + fn[1]\n    vc2 = tp[2] + fp[2] + tn[2] + fn[2]\n    vc3 = tp[3] + fp[3] + tn[3] + fn[3]\n    recall = sum(tp) / (vc1 + vc2 + vc3 + eps)\n    f1 = 2 * precision * recall / (precision + recall + eps)\n    print('precision = {}'.format(precision))\n    print('recall = {}'.format(recall))\n    print('f1 = {}'.format(f1))\n\n    return np.mean(losses), precision, recall, f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T02:10:31.424241Z","iopub.execute_input":"2025-05-07T02:10:31.424610Z","iopub.status.idle":"2025-05-07T02:10:31.448430Z","shell.execute_reply.started":"2025-05-07T02:10:31.424583Z","shell.execute_reply":"2025-05-07T02:10:31.447151Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"#test\ndef main():\n    # Configuration\n    batch_size = 1\n    num_epochs = 1000\n    lr = 0.0001\n    val_intervals = 1\n    train_steps_per_epoch = 200\n    val_steps_per_epoch = 200\n    exp_id = 'default'\n    \n    # Initialize datasets and loaders (same as before)\n    train_dataset = trackNetDataset('train',1280,720)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n    \n    val_dataset = trackNetDataset('val',1280,720)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n    \n    # Initialize model\n    model = BallTrackerNet()\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    model = model.to(device)\n    \n    # Setup logging\n    exps_path = f'/kaggle/working/exps/{exp_id}'\n    os.makedirs(exps_path, exist_ok=True)\n    log_writer = SummaryWriter(os.path.join(exps_path, 'plots'))\n    \n    # Model paths\n    model_last_path = os.path.join(exps_path, 'model_last.pth')\n    model_best_path = os.path.join(exps_path, 'model_best.pth')\n    \n    # Training setup\n    optimizer = optim.Adadelta(model.parameters(), lr=lr)\n    val_best_metric = -1  # Initialize to -1 instead of 0\n    \n    for epoch in range(num_epochs):\n        # Training phase\n        model.train()\n        train_losses = []\n        for batch_idx, batch in enumerate(train_loader):\n            if batch_idx >= train_steps_per_epoch:\n                break\n                \n            optimizer.zero_grad()\n            out = model(batch[0].float().to(device))\n            gt = batch[1].long().to(device)\n            loss = nn.CrossEntropyLoss()(out, gt)\n            loss.backward()\n            optimizer.step()\n            train_losses.append(loss.item())\n        \n        avg_train_loss = np.mean(train_losses)\n        print(f'Epoch {epoch+1} Train Loss: {avg_train_loss:.4f}')\n        \n        # Validation phase\n        if epoch % val_intervals == 0:\n            model.eval()\n            val_losses = []\n            all_tp, all_fp, all_tn, all_fn = 0, 0, 0, 0\n            \n            with torch.no_grad():\n                for batch_idx, batch in enumerate(val_loader):\n                    if batch_idx >= val_steps_per_epoch:\n                        break\n                        \n                    out = model(batch[0].float().to(device))\n                    gt = batch[1].long().to(device)\n                    val_losses.append(nn.CrossEntropyLoss()(out, gt).item())\n                    \n                    # Calculate metrics\n                    preds = out.argmax(dim=1).cpu().numpy()\n                    for i in range(len(preds)):\n                        x_pred, y_pred = postprocess(preds[i])\n                        x_gt, y_gt, vis = batch[2][i], batch[3][i], batch[4][i]\n                        \n                        if x_pred is not None:  # Prediction exists\n                            if vis != 0:  # Ball is visible\n                                dst = distance.euclidean((x_pred, y_pred), (x_gt, y_gt))\n                                if dst < 5:  # Correct prediction\n                                    all_tp += 1\n                                else:  # Wrong position\n                                    all_fp += 1\n                            else:  # False positive (predicted but no ball)\n                                all_fp += 1\n                        else:  # No prediction\n                            if vis != 0:  # Missed ball\n                                all_fn += 1\n                            else:  # Correct non-detection\n                                all_tn += 1\n            \n            # Calculate metrics\n            eps = 1e-7\n            precision = all_tp / (all_tp + all_fp + eps)\n            recall = all_tp / (all_tp + all_fn + eps)\n            f1 = 2 * (precision * recall) / (precision + recall + eps)\n            \n            print(f'Validation Metrics - Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}')\n            \n            # Always save last model\n            torch.save(model.state_dict(), model_last_path)\n            \n            # Save best model\n            if f1 > val_best_metric:\n                val_best_metric = f1\n                torch.save(model.state_dict(), model_best_path)\n                print(f'New best model saved with F1: {f1:.4f}')\n                \n    print(\"Training complete!\")\n    print(f\"Final best validation F1: {val_best_metric:.4f}\")\n\nif __name__ == '__main__':\n    main()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}